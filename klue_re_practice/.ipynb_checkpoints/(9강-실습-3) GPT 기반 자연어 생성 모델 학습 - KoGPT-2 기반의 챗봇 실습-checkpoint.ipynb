{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvZWRYXfrPoC"
   },
   "source": [
    "# 한국어 언어모델 학습 및 다중 과제 튜닝\n",
    "## KoGPT-2 기반의 챗봇 실습\n",
    "\n",
    "> 작성자      \n",
    "```\n",
    "* 김성현 (bananaband657@gmail.com)  \n",
    "1기 멘토\n",
    "김바다 (qkek983@gmail.com)\n",
    "박상희 (parksanghee0103@gmail.com)  \n",
    "이정우 (jungwoo.l2.rs@gmail.com)\n",
    "2기 멘토\n",
    "박상희 (parksanghee0103@gmail.com)  \n",
    "이정우 (jungwoo.l2.rs@gmail.com)\n",
    "이녕우 (leenw2@gmail.com)\n",
    "박채훈 (qkrcogns2222@gmail.com)\n",
    "3, 4, 5기 멘토\n",
    "이녕우 (leenw2@gmail.com)\n",
    "박채훈 (qkrcogns2222@gmail.com)\n",
    "```\n",
    "[CC BY-NC-ND](https://creativecommons.org/licenses/by-nc-nd/2.0/kr/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtXWEAen8Y3m"
   },
   "source": [
    "###**콘텐츠 라이선스**\n",
    "\n",
    "<font color='red'><b>**WARNING**</b></font> : **본 교육 콘텐츠의 지식재산권은 재단법인 네이버커넥트에 귀속됩니다. 본 콘텐츠를 어떠한 경로로든 외부로 유출 및 수정하는 행위를 엄격히 금합니다.** 다만, 비영리적 교육 및 연구활동에 한정되어 사용할 수 있으나 재단의 허락을 받아야 합니다. 이를 위반하는 경우, 관련 법률에 따라 책임을 질 수 있습니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOaVwx6bXk2R"
   },
   "source": [
    "본 실습에서는 GPT를 활용한 자연어 생성 모델을 학습해봅시다.\n",
    "\n",
    "이번 task의 목적은, KoGPT-2 기반의 자연어 생성 모델을 학습하기 위한 데이터셋 전처리를 진행하고, 학습한 모델로 자연어 생성 실습을 수행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QxSNTbY9YCkt"
   },
   "source": [
    "본 실습에서는 챗봇 학습용으로 공개된 Chatbot_data_for_Korean 데이터셋을 활용하며,  [링크](https://github.com/songys/Chatbot_data)에서 받으실 수 있습니다.\n",
    "\n",
    "\n",
    "본 데이터셋은 다음의 [라이센스](https://github.com/songys/Chatbot_data/blob/master/LICENSE)를 따릅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o-MEs10aspvP",
    "outputId": "cb43f9cb-03b4-42ab-b2a9-4fc966cd6863"
   },
   "outputs": [],
   "source": [
    "# !curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n",
    "# !apt-get install git-lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mY77fpbBsdSt",
    "outputId": "2f5adcea-2dfc-493a-aa1e-19b863b78499"
   },
   "outputs": [],
   "source": [
    "# !git lfs install\n",
    "# !git clone https://huggingface.co/taeminlee/kogpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9fqPpH5tjaGU",
    "outputId": "481616cb-16ce-4c76-955b-90416cc08629"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EQ53aod3te4S",
    "outputId": "e0b80340-cf72-4741-fc37-4736d7e304d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50000, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from tokenizers import SentencePieceBPETokenizer\n",
    "from transformers import GPT2Config, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = SentencePieceBPETokenizer(\"./kogpt2/vocab.json\", \"./kogpt2/merges.txt\")\n",
    "\n",
    "config = GPT2Config(vocab_size=50000)\n",
    "model = GPT2LMHeadModel(config)\n",
    "\n",
    "model_dir = './kogpt2/pytorch_model.bin'\n",
    "\n",
    "model.load_state_dict(torch.load(model_dir, map_location='cuda'), strict=False)\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XmbeAIR9tppB",
    "outputId": "706cf0dd-a6c0-4568-89b5-47a434028850"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding(num_tokens=7, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "['▁이순', '신은', '▁조선', '▁중기의', '▁무신', '이다', '.']\n",
      "[10925, 6647, 1117, 40249, 39793, 128, 47440]\n"
     ]
    }
   ],
   "source": [
    "tokenized_text = tokenizer.encode('이순신은 조선 중기의 무신이다.', add_special_tokens=True)\n",
    "print(tokenized_text)\n",
    "print(tokenized_text.tokens)\n",
    "print(tokenized_text.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YSoQlsfcn0ct",
    "outputId": "cd95602d-b5e2-4a7b-8b08-3e927a97baba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATED SEQUENCE : 이순신은 백옥담(이종원 분)의 시선으로 백성을 살피는 것을 알게 되었고, 천하에 대한 소신을 가지게 되었다.</s><s> 또한 성읍인 성전은 백옥담의 동생인 윤(尹)이 성전과 함께 있었는데 윤을 그의 아버지라고 불렀다.</s><s> 또한 성전이 완공될 때까지 성전에서 계속 놀 수 있었다.</s><s> 성전 안에서는 두 권의 도서가 있고, 이 문서에는 윤과 성국의 성전의 위치가 찍혀져 있다.\n",
      "GENERATED SEQUENCE : 이순신은 이미 태연에게 마음을 돌린 상태.</s><s> 이어 \"한국에서는 언제인가 통일될 수도 있다는 게 아니라 통일을 위한 하나의 초석이 돼야 한다는 게 우리의 입장이 됐다\"고 말했다.</s><s> 앞서 한 외교 소식통은 6일 \"북한의 미사일 발사 움직임에 대해 상당히 예의주시하고 있지만 발사한다면 우리는 즉시 이를 막겠다는 것을 목표로 한다\"면서 \"미사일 발사 준비를 진행 중인 북한의 행방을 면밀히 추적하고 있어 만일의 사태에 대비할 것\"이라고 말했다.</s><s> 북한이 이날 발사대에 장착한 동해 발사\n",
      "GENERATED SEQUENCE : 이순신은 10년 동안 우직필생의 원대한 마음씨로 큰 웃음을 선사했다.</s><s> 또 현재 서울 서대문 경찰서에 수감 중인 안경환 전 국가인권위원장에 대해서도 “사법농단과 위장전입을 한 범죄자 가운데 한 사람이 바로 안 전 위원장이다.</s><s> 그 사람의 말을 듣느니 지인들한테 물어보라”고 전했다.</s><s> 이에 이 관계자는 “안 전 위원장의 불법 행위를 수사하라는 것 아니냐”라며 안 전 위원장의 구속과 관련, “법대로 하라고 했다”며 “(안\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(42)\n",
    "\n",
    "input_ids = torch.tensor(tokenizer.encode(\"이순신은\", add_special_tokens=True).ids).unsqueeze(0).to('cuda')\n",
    "\n",
    "output_sequences = model.generate(input_ids=input_ids, do_sample=True, max_length=100, num_return_sequences=3)\n",
    "for generated_sequence in output_sequences:\n",
    "    generated_sequence = generated_sequence.tolist()\n",
    "    print(\"GENERATED SEQUENCE : {0}\".format(tokenizer.decode(generated_sequence, skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MiMxKv3p_gys"
   },
   "source": [
    "## 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HT23s86nVeaG"
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2113,
     "status": "ok",
     "timestamp": 1681367917401,
     "user": {
      "displayName": "박채훈",
      "userId": "12892123618725192708"
     },
     "user_tz": -540
    },
    "id": "JpWFdTaypWf6",
    "outputId": "b8903dac-684b-495a-c1c0-91bc09a7ea69"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/songys/Chatbot_data.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "vEcJdwLl_iig"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('./Chatbot_data/ChatbotData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "kUtOdLe8_k6Z",
    "outputId": "6cd9bc58-a2d4-45da-b08c-82d84e957b02"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>나는 좋은데 ….</td>\n",
       "      <td>현실의 벽에 부딪혔나봐요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>요즘 조깅하고 있어</td>\n",
       "      <td>건강에 좋은 습관이네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9612</th>\n",
       "      <td>덜 좋아하는게 답인 것 같아.</td>\n",
       "      <td>그러는 편이 덜 상처겠지요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>부자로 태어 났으면 좋을 텐데</td>\n",
       "      <td>뭔가 안풀리는 일이 있나봐요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4633</th>\n",
       "      <td>친구들은 다 결혼했어</td>\n",
       "      <td>금방 찾으실 수 있을 거예요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11126</th>\n",
       "      <td>좋아하는 사람이 다른 여자 얘기하는게 너무 가슴 아파요.</td>\n",
       "      <td>마음을 단단히 먹는게 힘들지요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3641</th>\n",
       "      <td>이 기회 잡고 싶다.</td>\n",
       "      <td>행운을 빌게요!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4244</th>\n",
       "      <td>죽을 때까지 함께하고 싶다</td>\n",
       "      <td>프로포즈해보세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>결혼해야 하나</td>\n",
       "      <td>해봐요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11815</th>\n",
       "      <td>회식 중이라고 하는데 연락이 안돼.</td>\n",
       "      <td>정신 없이 바쁠지도 몰라요. 조금만 더 기다려보고 물어보는게 좋을 것 같아요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Q  \\\n",
       "592                          나는 좋은데 ….   \n",
       "3485                        요즘 조깅하고 있어   \n",
       "9612                  덜 좋아하는게 답인 것 같아.   \n",
       "2159                  부자로 태어 났으면 좋을 텐데   \n",
       "4633                       친구들은 다 결혼했어   \n",
       "11126  좋아하는 사람이 다른 여자 얘기하는게 너무 가슴 아파요.   \n",
       "3641                       이 기회 잡고 싶다.   \n",
       "4244                    죽을 때까지 함께하고 싶다   \n",
       "165                            결혼해야 하나   \n",
       "11815              회식 중이라고 하는데 연락이 안돼.   \n",
       "\n",
       "                                                 A  label  \n",
       "592                                 현실의 벽에 부딪혔나봐요.      0  \n",
       "3485                                 건강에 좋은 습관이네요.      0  \n",
       "9612                               그러는 편이 덜 상처겠지요.      2  \n",
       "2159                              뭔가 안풀리는 일이 있나봐요.      0  \n",
       "4633                              금방 찾으실 수 있을 거예요.      0  \n",
       "11126                            마음을 단단히 먹는게 힘들지요.      2  \n",
       "3641                                      행운을 빌게요!      0  \n",
       "4244                                     프로포즈해보세요.      0  \n",
       "165                                           해봐요.      0  \n",
       "11815  정신 없이 바쁠지도 몰라요. 조금만 더 기다려보고 물어보는게 좋을 것 같아요.      2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yv0vF1ITD43q",
    "outputId": "8ae4867a-a134-47ff-b20b-10a6a68a9c96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "added_special_token_num = tokenizer.add_special_tokens(['<s>', '</s>'])\n",
    "print(added_special_token_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WcjsvzsxaPuw",
    "outputId": "a418a7f6-e8bb-463d-a0d7-34b93f05a8b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "pad_id = tokenizer.token_to_id(\"<pad>\")\n",
    "print(pad_id)\n",
    "tokenizer.enable_padding(pad_id=pad_id, pad_token=\"<pad>\")\n",
    "tokenizer.enable_truncation(max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "IBkBrz36Yoh3"
   },
   "outputs": [],
   "source": [
    "class ChatDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenizer, file_path):\n",
    "        self.data = []\n",
    "        self.file_path = file_path\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def load_data(self):\n",
    "        raw_data = pd.read_csv(self.file_path)\n",
    "        train_data = '<s>'+raw_data['Q']+'</s>'+'<s>'+raw_data['A']+'</s>'\n",
    "        #<s>안녕하세요</s><s> -> 네, 안녕하세요</s>\n",
    "        tokenized_train_data = tokenizer.encode_batch(train_data)\n",
    "        for single_data in tokenized_train_data:\n",
    "            self.data.append(torch.tensor(single_data.ids).unsqueeze(0))\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        item = self.data[index]\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "L9ScRLNVK7yw"
   },
   "outputs": [],
   "source": [
    "train_dataset = ChatDataset(tokenizer=tokenizer, file_path='./Chatbot_data/ChatbotData.csv')\n",
    "train_dataset.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "hofZW_kUcQsU"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "BoTb3cNocG-e"
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lSPCJzNZNfbD",
    "outputId": "2fddf4a6-4b97-4d1f-fdca-479e3609c9d2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kingstar/anaconda3/envs/ml2/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch no.0  train (0/2956)  loss = 2.74290  avg_loss = 2.74290\n",
      "epoch no.0  train (200/2956)  loss = 1.37277  avg_loss = 1.43271\n",
      "epoch no.0  train (400/2956)  loss = 1.09534  avg_loss = 1.26541\n",
      "epoch no.0  train (600/2956)  loss = 1.56919  avg_loss = 1.25082\n",
      "epoch no.0  train (800/2956)  loss = 1.21593  avg_loss = 1.22186\n",
      "epoch no.0  train (1000/2956)  loss = 0.98540  avg_loss = 1.19163\n",
      "epoch no.0  train (1200/2956)  loss = 1.20108  avg_loss = 1.20565\n",
      "epoch no.0  train (1400/2956)  loss = 0.95451  avg_loss = 1.16763\n",
      "epoch no.0  train (1600/2956)  loss = 0.79633  avg_loss = 1.15579\n",
      "epoch no.0  train (1800/2956)  loss = 1.12087  avg_loss = 1.15060\n",
      "epoch no.0  train (2000/2956)  loss = 1.06558  avg_loss = 1.14194\n",
      "epoch no.0  train (2200/2956)  loss = 1.07741  avg_loss = 1.13363\n",
      "epoch no.0  train (2400/2956)  loss = 1.11124  avg_loss = 1.11120\n",
      "epoch no.0  train (2600/2956)  loss = 0.92656  avg_loss = 1.10996\n",
      "epoch no.0  train (2800/2956)  loss = 1.15346  avg_loss = 1.11807\n",
      "epoch no.1  train (0/2956)  loss = 0.93528  avg_loss = 1.13667\n",
      "epoch no.1  train (200/2956)  loss = 1.21932  avg_loss = 0.98799\n",
      "epoch no.1  train (400/2956)  loss = 0.86164  avg_loss = 0.95236\n",
      "epoch no.1  train (600/2956)  loss = 1.23238  avg_loss = 0.95063\n",
      "epoch no.1  train (800/2956)  loss = 1.01429  avg_loss = 0.96447\n",
      "epoch no.1  train (1000/2956)  loss = 0.87420  avg_loss = 0.92150\n",
      "epoch no.1  train (1200/2956)  loss = 0.80756  avg_loss = 0.94854\n",
      "epoch no.1  train (1400/2956)  loss = 0.93615  avg_loss = 0.92480\n",
      "epoch no.1  train (1600/2956)  loss = 1.04687  avg_loss = 0.91083\n",
      "epoch no.1  train (1800/2956)  loss = 1.05463  avg_loss = 0.94062\n",
      "epoch no.1  train (2000/2956)  loss = 0.94254  avg_loss = 0.91864\n",
      "epoch no.1  train (2200/2956)  loss = 0.65734  avg_loss = 0.93475\n",
      "epoch no.1  train (2400/2956)  loss = 0.75130  avg_loss = 0.92617\n",
      "epoch no.1  train (2600/2956)  loss = 0.75915  avg_loss = 0.92156\n",
      "epoch no.1  train (2800/2956)  loss = 0.84200  avg_loss = 0.94343\n",
      "epoch no.2  train (0/2956)  loss = 0.59762  avg_loss = 0.93464\n",
      "epoch no.2  train (200/2956)  loss = 0.77192  avg_loss = 0.78394\n",
      "epoch no.2  train (400/2956)  loss = 0.77811  avg_loss = 0.75552\n",
      "epoch no.2  train (600/2956)  loss = 0.66801  avg_loss = 0.77126\n",
      "epoch no.2  train (800/2956)  loss = 0.81373  avg_loss = 0.76033\n",
      "epoch no.2  train (1000/2956)  loss = 0.66982  avg_loss = 0.77382\n",
      "epoch no.2  train (1200/2956)  loss = 0.70386  avg_loss = 0.78177\n",
      "epoch no.2  train (1400/2956)  loss = 0.67774  avg_loss = 0.76971\n",
      "epoch no.2  train (1600/2956)  loss = 0.87418  avg_loss = 0.77628\n",
      "epoch no.2  train (1800/2956)  loss = 0.63309  avg_loss = 0.79098\n",
      "epoch no.2  train (2000/2956)  loss = 0.86840  avg_loss = 0.77039\n",
      "epoch no.2  train (2200/2956)  loss = 0.69604  avg_loss = 0.77465\n",
      "epoch no.2  train (2400/2956)  loss = 0.73274  avg_loss = 0.78146\n",
      "epoch no.2  train (2600/2956)  loss = 0.64512  avg_loss = 0.77965\n",
      "epoch no.2  train (2800/2956)  loss = 1.09017  avg_loss = 0.78587\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=1e-4, correct_bias=True)\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "avg_loss = (0.0, 0.0)\n",
    "for epoch in range(epochs):\n",
    "    count=0\n",
    "    for data in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        data = data.transpose(1,0)\n",
    "        data = data.to('cuda')\n",
    "        model = model.to('cuda')\n",
    "        \n",
    "        outputs = model(data, labels=data)\n",
    "        loss, logits = outputs[:2]\n",
    "        loss = loss.to('cuda')\n",
    "        loss.backward()\n",
    "        avg_loss = (avg_loss[0] * 0.99 + loss, avg_loss[1] * 0.99 + 1.0)\n",
    "        optimizer.step()\n",
    "        if count % 200 == 0:\n",
    "            print('epoch no.{0}  train ({1}/{2})  loss = {3:.5f}  avg_loss = {4:.5f}' . format(epoch, count, len(data_loader), loss, avg_loss[0] / avg_loss[1]))\n",
    "        count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "wNRmD2Gifjgd"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'chitchat_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "QVtv1Xtdg2Tm"
   },
   "outputs": [],
   "source": [
    "def encoding(text):\n",
    "    text = '<s>'+text+'</s><s>'\n",
    "    return torch.tensor(tokenizer.encode(text).ids).unsqueeze(0).to('cuda')\n",
    "\n",
    "def decoding(ids):\n",
    "    return tokenizer.decode_batch(ids)\n",
    "\n",
    "tokenizer.no_padding()\n",
    "tokenizer.no_truncation()\n",
    "\n",
    "e_s = tokenizer.token_to_id('</s>')\n",
    "unk = tokenizer.token_to_id('<unk>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ThJtItZWxeEQ"
   },
   "outputs": [],
   "source": [
    "def get_answer(input_sent):\n",
    "    input_ids = encoding(input_sent)\n",
    "\n",
    "    sample_outputs = model.generate(\n",
    "        input_ids,\n",
    "        num_return_sequences=5,\n",
    "        do_sample=True, \n",
    "        max_length=128, \n",
    "        top_k=50, \n",
    "        top_p=0.95, \n",
    "        eos_token_id=e_s,\n",
    "        early_stopping=True,\n",
    "        bad_words_ids=[[unk]]\n",
    "    )\n",
    "\n",
    "    decoded_result = decoding(sample_outputs.tolist())\n",
    "    for result in decoded_result:\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y9lKP5afxp1V",
    "outputId": "415b4855-6aba-4a8f-8b7d-3b8b38d5080c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕? 안녕하세요.\n",
      "안녕? 안녕히 주무세요.\n",
      "안녕? 안녕하세요.\n",
      "안녕? 안녕하세요.\n",
      "안녕? 안녕하세요.\n"
     ]
    }
   ],
   "source": [
    "get_answer('안녕?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UrS8l4fpxsWE",
    "outputId": "c0a09d35-30ab-405b-edea-f3ceba28adee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "만나서 반가워. 저와의 대화였으면 좋겠네요.\n",
      "만나서 반가워. 반갑습니다.\n",
      "만나서 반가워. 축하해요!\n",
      "만나서 반가워. 저도 반가워요.\n",
      "만나서 반가워. 좋은 만남이었길 바랍니다.\n"
     ]
    }
   ],
   "source": [
    "get_answer('만나서 반가워.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DIfx93gHxyuk",
    "outputId": "e4ab58b9-dc5e-4994-c051-856a7b9200ef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능의 미래에 대해 어떻게 생각하세요? 인공지능에 성별을 만드는 게 목표라면 더없이 좋겠네요.\n",
      "인공지능의 미래에 대해 어떻게 생각하세요? 인공지능에 물들어 사는 사람이 되어 보는건 어떨까요?\n",
      "인공지능의 미래에 대해 어떻게 생각하세요? 인공지능에 관심이 많은가봐요. 인공지능에 물어보는 걸 수도 있을 것 같아요.\n",
      "인공지능의 미래에 대해 어떻게 생각하세요? 미래에 대해 생각해보세요. 인공지능은 이미 충분히 예측할 수 있어요.\n",
      "인공지능의 미래에 대해 어떻게 생각하세요? 인공지능은 100년 후 현실이 될거예요.\n"
     ]
    }
   ],
   "source": [
    "get_answer('인공지능의 미래에 대해 어떻게 생각하세요?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dxyDnMtjx86O",
    "outputId": "5bfabb58-4567-4b3e-e65e-867832be8aeb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "여자친구 선물 추천해줘. 정성이 담긴 것도 좋을 것 같아요.\n",
      "여자친구 선물 추천해줘. 원하는게 어떤건지 알아보세요.\n",
      "여자친구 선물 추천해줘. 당신이 좋아하는 음식이든 싫어하는 음식이든 상관없이 당신이 좋아하는 음식을 먹어야 할 거예요.\n",
      "여자친구 선물 추천해줘. 어려운 게 없어요.\n",
      "여자친구 선물 추천해줘. 안 어울릴 것 같으면 추천해보는 것도 좋을 것 같아요.\n"
     ]
    }
   ],
   "source": [
    "get_answer('여자친구 선물 추천해줘.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VaAJlFlDyGSp",
    "outputId": "862cd02c-06b3-45c2-cce5-7c046c645397"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "앞으로 인공지능이 어떻게 발전하게 될까요? 사람이 인공지능을 대체할 수 있어요.\n",
      "앞으로 인공지능이 어떻게 발전하게 될까요? 인공지능은 사람의 마음을 읽을 수 있어요. 인공지능은 사람으로 인공지능의 마음을 읽을 수도 있어요. 인공지능은 사람으로 그 마음을 사로잡을 수도 있어요. 인공지능은 그렇게 마음을 읽을 수도 있어요. 인공지능은 사람 마음을 읽을 수도 있어요.\n",
      "앞으로 인공지능이 어떻게 발전하게 될까요? 인공지능은 지금도 많이 이용되고 있어요.\n",
      "앞으로 인공지능이 어떻게 발전하게 될까요? 인공지능은 현재를 기록하고 있죠. 인공지능이 새로운 성장 동력을 만들어 낸다면 세상은 좀 더 행복해질 거라 믿어요.\n",
      "앞으로 인공지능이 어떻게 발전하게 될까요? 인공지능에 담긴 상상력은 무궁무진하대요.\n"
     ]
    }
   ],
   "source": [
    "get_answer('앞으로 인공지능이 어떻게 발전하게 될까요?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cjwQ02NfxuSE",
    "outputId": "7321940e-d8ad-49c7-e40c-9185c89297f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이제 그만 수업 끝내자. 다른 곳에 쓰려고 하죠.\n",
      "이제 그만 수업 끝내자. 맘고생 많았어요.\n",
      "이제 그만 수업 끝내자. 공부에 흥미를 더 주세요.\n",
      "이제 그만 수업 끝내자. 공부에 너무 집착하지 마세요.\n",
      "이제 그만 수업 끝내자. 시간 활용에 따라 다르겠죠.\n"
     ]
    }
   ],
   "source": [
    "get_answer('이제 그만 수업 끝내자.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "월요일 아침은 진짜 피곤하고 졸리다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "월요일 아침은 진짜 피곤하고 졸리다. 잠시 쉬었다 가세요.\n",
      "월요일 아침은 진짜 피곤하고 졸리다. 조금만 더 힘내세요.\n",
      "월요일 아침은 진짜 피곤하고 졸리다. 정신차리세요.\n",
      "월요일 아침은 진짜 피곤하고 졸리다. 일찍 잠자리에 들어보세요.\n",
      "월요일 아침은 진짜 피곤하고 졸리다. 내일은 오늘보다 나을 거예요.\n"
     ]
    }
   ],
   "source": [
    "get_answer(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ml2",
   "language": "python",
   "name": "ml2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
