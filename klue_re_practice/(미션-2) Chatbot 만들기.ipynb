{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "037f1be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2fdab10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f75e6b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_data_path = './Chatbot_data/ChatbotData.csv'\n",
    "chat_data = pd.read_csv(chat_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fd5cc7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>다시 돌아오거나 연락이 올까.</td>\n",
       "      <td>간절히 원한다면 지금 연락해보세요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>나한테 문제가 많아</td>\n",
       "      <td>문제는 해결하라고 있는 거죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3179</th>\n",
       "      <td>여친이 맨날 욕해</td>\n",
       "      <td>사람 고쳐쓰는 거 아니에요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5107</th>\n",
       "      <td>헤어지자</td>\n",
       "      <td>좋은 선택이길 바랄게요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>건강한 다이어트법</td>\n",
       "      <td>적게 먹고 많이 움직이세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7717</th>\n",
       "      <td>이제 힘내렵니다!</td>\n",
       "      <td>당신이 기운내는 것을 보니 좋은 예감이 들어요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>봄에 동물원 데이트 어때?</td>\n",
       "      <td>동심으로 돌아갈 거 같아요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3257</th>\n",
       "      <td>영화보고 왔다</td>\n",
       "      <td>저도 영화 보여주세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11535</th>\n",
       "      <td>짝녀랑 카톡했던거 다시 읽어 보는데 거의 다만 물어보네.</td>\n",
       "      <td>상대분이 아직 관심이 덜한 걸 수도 있어요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7292</th>\n",
       "      <td>우정이란게 뭘까</td>\n",
       "      <td>힘들 때 같이 있는 거요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>남자친구가 이벤트를 잘 안해줘</td>\n",
       "      <td>당신이 해보세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5732</th>\n",
       "      <td>꿈에서라도 보고싶어</td>\n",
       "      <td>꿈에서 본다면 더 마음이 헛헛할 거예요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10982</th>\n",
       "      <td>장난인지 진심인지 구분이 안돼.</td>\n",
       "      <td>직접적으로 물어보는 게 가장 확실하겠죠.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4087</th>\n",
       "      <td>전화 안 받아</td>\n",
       "      <td>연락두절돼서 걱정되겠네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9322</th>\n",
       "      <td>남자친구가 돈이 너무 없어.</td>\n",
       "      <td>정말 현실적인 문제네요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2369</th>\n",
       "      <td>새로운 베프를 만들고 싶어</td>\n",
       "      <td>주변의 좋은 사람들에게 연락해보세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4834</th>\n",
       "      <td>투잡 뛰어야 하나?</td>\n",
       "      <td>필요하다면요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3283</th>\n",
       "      <td>오늘 너무 졸려</td>\n",
       "      <td>오늘 일찍 주무세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>뉴스는 역시 지루해</td>\n",
       "      <td>흥미를 가져보세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10763</th>\n",
       "      <td>영원히 함께 했으면 좋겠다</td>\n",
       "      <td>마음은 언제나 함께할 거예요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Q                           A  label\n",
       "6036                  다시 돌아오거나 연락이 올까.         간절히 원한다면 지금 연락해보세요.      1\n",
       "663                         나한테 문제가 많아            문제는 해결하라고 있는 거죠.      0\n",
       "3179                         여친이 맨날 욕해             사람 고쳐쓰는 거 아니에요.      0\n",
       "5107                              헤어지자               좋은 선택이길 바랄게요.      0\n",
       "114                          건강한 다이어트법             적게 먹고 많이 움직이세요.      0\n",
       "7717                         이제 힘내렵니다!  당신이 기운내는 것을 보니 좋은 예감이 들어요.      1\n",
       "2130                    봄에 동물원 데이트 어때?             동심으로 돌아갈 거 같아요.      0\n",
       "3257                           영화보고 왔다                저도 영화 보여주세요.      0\n",
       "11535  짝녀랑 카톡했던거 다시 읽어 보는데 거의 다만 물어보네.    상대분이 아직 관심이 덜한 걸 수도 있어요.      2\n",
       "7292                          우정이란게 뭘까              힘들 때 같이 있는 거요.      1\n",
       "742                   남자친구가 이벤트를 잘 안해줘                   당신이 해보세요.      0\n",
       "5732                        꿈에서라도 보고싶어      꿈에서 본다면 더 마음이 헛헛할 거예요.      1\n",
       "10982                장난인지 진심인지 구분이 안돼.      직접적으로 물어보는 게 가장 확실하겠죠.      2\n",
       "4087                           전화 안 받아              연락두절돼서 걱정되겠네요.      0\n",
       "9322                   남자친구가 돈이 너무 없어.               정말 현실적인 문제네요.      2\n",
       "2369                    새로운 베프를 만들고 싶어        주변의 좋은 사람들에게 연락해보세요.      0\n",
       "4834                        투잡 뛰어야 하나?                     필요하다면요.      0\n",
       "3283                          오늘 너무 졸려                 오늘 일찍 주무세요.      0\n",
       "1088                        뉴스는 역시 지루해                  흥미를 가져보세요.      0\n",
       "10763                   영원히 함께 했으면 좋겠다            마음은 언제나 함께할 거예요.      2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_data.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbe381a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = \"bert-base-multilingual-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adc96a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cls_token(sent_A):\n",
    "    model.to(device).eval()\n",
    "    tokenized_sent = tokenizer(\n",
    "            sent_A,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=128\n",
    "    )\n",
    "    with torch.no_grad():# 그라디엔트 계산 비활성화\n",
    "        outputs = model(    # **tokenized_sent\n",
    "            input_ids=tokenized_sent['input_ids'].to(device),\n",
    "            attention_mask=tokenized_sent['attention_mask'].to(device),\n",
    "            token_type_ids=tokenized_sent['token_type_ids'].to(device)\n",
    "            )\n",
    "    logits = outputs.last_hidden_state[:,0,:].detach().cpu()\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e1185a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized 1000 words\n",
      "Tokenized 2000 words\n",
      "Tokenized 3000 words\n",
      "Tokenized 4000 words\n",
      "Tokenized 5000 words\n",
      "Tokenized 6000 words\n",
      "Tokenized 7000 words\n",
      "Tokenized 8000 words\n",
      "Tokenized 9000 words\n",
      "Tokenized 10000 words\n",
      "Tokenized 11000 words\n",
      "torch.Size([11823, 768])\n"
     ]
    }
   ],
   "source": [
    "dataset_cls_hidden = []\n",
    "itr = 0\n",
    "for q in chat_data.Q:\n",
    "    itr += 1\n",
    "    q_cls = get_cls_token(q).to(device)\n",
    "    dataset_cls_hidden.append(torch.Tensor(q_cls))\n",
    "    if itr % 1000 ==0:\n",
    "        print(f'Tokenized {itr} words')\n",
    "dataset_cls_hidden = torch.stack(dataset_cls_hidden).squeeze(axis=1)\n",
    "# print(dataset_cls_hidden)   # 데이터셋의 질문에 대한 [CLS] 토큰 벡터\n",
    "print(dataset_cls_hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1917df6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 잠 깨는 음악 하나만 추천해줘\n",
      "A:  애국가요.\n"
     ]
    }
   ],
   "source": [
    "my_question = input('Q: ')\n",
    "my_question_cls_hidden = get_cls_token(my_question)\n",
    "\n",
    "cos_sim = cosine_similarity(my_question_cls_hidden.detach().cpu(), dataset_cls_hidden.detach().cpu()).flatten()\n",
    "\n",
    "top_question = np.argmax(cos_sim)\n",
    "\n",
    "print('A: ', chat_data.iloc[top_question].A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411c5233",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2",
   "language": "python",
   "name": "ml2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
