{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "btDmoiRCRfMp"
   },
   "source": [
    "## **1. NaiveBayes Classifier**\n",
    "1. 주어진 데이터를 전처리합니다.\n",
    "2. NaiveBayes 분류기 모델을 구현하고 학습 데이터로 이를 학습시킵니다.\n",
    "3. 간단한 test case로 결과를 확인합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3a3E1pbkSYSF"
   },
   "source": [
    "### **필요 패키지 import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6GKm6PwhiGxv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting konlpy\n",
      "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /home/kingstar/anaconda3/envs/ml/lib/python3.10/site-packages (from konlpy) (1.23.5)\n",
      "Collecting JPype1>=0.7.0\n",
      "  Downloading JPype1-1.4.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.3/465.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /home/kingstar/anaconda3/envs/ml/lib/python3.10/site-packages (from konlpy) (4.9.1)\n",
      "Requirement already satisfied: packaging in /home/kingstar/.local/lib/python3.10/site-packages (from JPype1>=0.7.0->konlpy) (23.0)\n",
      "Installing collected packages: JPype1, konlpy\n",
      "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2srhF-lp4JxL"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 다양한 한국어 형태소 분석기가 클래스로 구현되어 있음\n",
    "from konlpy import tag \n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import chain\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rpgjbzqr6UR4"
   },
   "source": [
    "### **학습 및 테스트 데이터 전처리**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTRXq_6G7wTk"
   },
   "source": [
    "Sample 데이터를 확인해 봅시다.\n",
    "긍정($1$), 부정($0$) 2가지 class로 구성되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MCBnEQrfoL_C"
   },
   "outputs": [],
   "source": [
    "train_data = [\n",
    "  \"정말 맛있습니다. 추천합니다.\",\n",
    "  \"기대했던 것보단 별로였네요.\",\n",
    "  \"다 좋은데 가격이 너무 비싸서 다시 가고 싶다는 생각이 안 드네요.\",\n",
    "  \"완전 최고입니다! 재방문 의사 있습니다.\",\n",
    "  \"음식도 서비스도 다 만족스러웠습니다.\",\n",
    "  \"위생 상태가 좀 별로였습니다. 좀 더 개선되기를 바랍니다.\",\n",
    "  \"맛도 좋았고 직원분들 서비스도 너무 친절했습니다.\",\n",
    "  \"기념일에 방문했는데 음식도 분위기도 서비스도 다 좋았습니다.\",\n",
    "  \"전반적으로 음식이 너무 짰습니다. 저는 별로였네요.\",\n",
    "  \"위생에 조금 더 신경 썼으면 좋겠습니다. 조금 불쾌했습니다.\"\n",
    "]\n",
    "train_labels = [1, 0, 0, 1, 1, 0, 1, 1, 0, 0]\n",
    "\n",
    "test_data = [\n",
    "  \"정말 좋았습니다. 또 가고 싶네요.\",\n",
    "  \"별로였습니다. 되도록 가지 마세요.\",\n",
    "  \"다른 분들께도 추천드릴 수 있을 만큼 만족했습니다.\",\n",
    "  \"서비스가 좀 더 개선되었으면 좋겠습니다. 기분이 좀 나빴습니다.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQ7rMLICacVN"
   },
   "source": [
    "KoNLPy 패키지에서 제공하는 Twitter(Okt) 토큰화기를 사용하여 토큰화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bEzeYDmPjNLl"
   },
   "outputs": [],
   "source": [
    "tokenizer = tag.Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Tftxirx_7sk7"
   },
   "outputs": [],
   "source": [
    "def make_tokenized(data):\n",
    "  tokenized = []  # 단어 단위로 나뉜 리뷰 데이터.\n",
    "\n",
    "  for sent in tqdm(data):\n",
    "    tokens = tokenizer.morphs(sent)\n",
    "    tokenized.append(tokens)\n",
    "\n",
    "  return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "I4VEZyFlCqi-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 401.48it/s]\n"
     ]
    }
   ],
   "source": [
    "train_tokenized = make_tokenized(train_data)\n",
    "test_tokenized = make_tokenized(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "OEhn3uv2o2kt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['정말', '맛있습니다', '.', '추천', '합니다', '.'],\n",
       " ['기대했던', '것', '보단', '별로', '였네요', '.'],\n",
       " ['다',\n",
       "  '좋은데',\n",
       "  '가격',\n",
       "  '이',\n",
       "  '너무',\n",
       "  '비싸서',\n",
       "  '다시',\n",
       "  '가고',\n",
       "  '싶다는',\n",
       "  '생각',\n",
       "  '이',\n",
       "  '안',\n",
       "  '드네',\n",
       "  '요',\n",
       "  '.'],\n",
       " ['완전', '최고', '입니다', '!', '재', '방문', '의사', '있습니다', '.'],\n",
       " ['음식', '도', '서비스', '도', '다', '만족스러웠습니다', '.'],\n",
       " ['위생',\n",
       "  '상태',\n",
       "  '가',\n",
       "  '좀',\n",
       "  '별로',\n",
       "  '였습니다',\n",
       "  '.',\n",
       "  '좀',\n",
       "  '더',\n",
       "  '개선',\n",
       "  '되',\n",
       "  '기를',\n",
       "  '바랍니다',\n",
       "  '.'],\n",
       " ['맛', '도', '좋았고', '직원', '분들', '서비스', '도', '너무', '친절했습니다', '.'],\n",
       " ['기념일',\n",
       "  '에',\n",
       "  '방문',\n",
       "  '했는데',\n",
       "  '음식',\n",
       "  '도',\n",
       "  '분위기',\n",
       "  '도',\n",
       "  '서비스',\n",
       "  '도',\n",
       "  '다',\n",
       "  '좋았습니다',\n",
       "  '.'],\n",
       " ['전반', '적', '으로', '음식', '이', '너무', '짰습니다', '.', '저', '는', '별로', '였네요', '.'],\n",
       " ['위생', '에', '조금', '더', '신경', '썼으면', '좋겠습니다', '.', '조금', '불쾌했습니다', '.']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVPd7lQjbfNO"
   },
   "source": [
    "토큰화된 단어들을 숫자로 변환할 수 있도록 학습 자료의 모든 단어들을 vocaburary에 추가하고, 단어를 숫자로, 숫자를 단어로 바꾸는 객체를 만들어 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tI2p2T1CJMlB"
   },
   "outputs": [],
   "source": [
    "i2w = list(set(chain.from_iterable(train_tokenized)))\n",
    "w2i = {w: i for i, w in enumerate(i2w)}                 # Key: 단어, Value: 단어의 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "cG3kuKkNKj0Z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "XIy3zcUSXNuR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'불쾌했습니다': 0,\n",
       " '음식': 1,\n",
       " '에': 2,\n",
       " '기념일': 3,\n",
       " '싶다는': 4,\n",
       " '드네': 5,\n",
       " '합니다': 6,\n",
       " '상태': 7,\n",
       " '이': 8,\n",
       " '직원': 9,\n",
       " '정말': 10,\n",
       " '완전': 11,\n",
       " '최고': 12,\n",
       " '입니다': 13,\n",
       " '서비스': 14,\n",
       " '였네요': 15,\n",
       " '짰습니다': 16,\n",
       " '신경': 17,\n",
       " '방문': 18,\n",
       " '기대했던': 19,\n",
       " '였습니다': 20,\n",
       " '좋았고': 21,\n",
       " '저': 22,\n",
       " '!': 23,\n",
       " '비싸서': 24,\n",
       " '맛있습니다': 25,\n",
       " '것': 26,\n",
       " '요': 27,\n",
       " '분위기': 28,\n",
       " '의사': 29,\n",
       " '맛': 30,\n",
       " '만족스러웠습니다': 31,\n",
       " '좋은데': 32,\n",
       " '분들': 33,\n",
       " '가고': 34,\n",
       " '생각': 35,\n",
       " '좋았습니다': 36,\n",
       " '으로': 37,\n",
       " '좋겠습니다': 38,\n",
       " '위생': 39,\n",
       " '썼으면': 40,\n",
       " '추천': 41,\n",
       " '바랍니다': 42,\n",
       " '도': 43,\n",
       " '재': 44,\n",
       " '했는데': 45,\n",
       " '적': 46,\n",
       " '가격': 47,\n",
       " '너무': 48,\n",
       " '다시': 49,\n",
       " '좀': 50,\n",
       " '별로': 51,\n",
       " '는': 52,\n",
       " '친절했습니다': 53,\n",
       " '개선': 54,\n",
       " '다': 55,\n",
       " '더': 56,\n",
       " '안': 57,\n",
       " '되': 58,\n",
       " '보단': 59,\n",
       " '가': 60,\n",
       " '조금': 61,\n",
       " '있습니다': 62,\n",
       " '.': 63,\n",
       " '전반': 64,\n",
       " '기를': 65}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85oCOe0Xqcwk"
   },
   "source": [
    "### **모델 Class 구현**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3uuFi52qjh6"
   },
   "source": [
    "NaiveBayes Classifier 모델 클래스를 구현해 봅시다.\n",
    "\n",
    "*   `self.k`: Smoothing을 위한 상수.\n",
    "*   `self.w2i`: 사전에 구한 vocab.\n",
    "*   `self.priors`: 각 class의 prior 확률.\n",
    "*   `self.likelihoods`: 각 token의 특정 class 조건 내에서의 likelihood.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "TsZlgjkBHAod"
   },
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier():\n",
    "  def __init__(self, w2i, k=0.1):\n",
    "    self.k = k\n",
    "    self.w2i = w2i\n",
    "    self.priors = {}\n",
    "    self.likelihoods = {}\n",
    "\n",
    "  def train(self, train_tokenized, train_labels):\n",
    "    self.set_priors(train_labels)  # Priors 계산.\n",
    "    self.set_likelihoods(train_tokenized, train_labels)  # Likelihoods 계산.\n",
    "\n",
    "  def inference(self, tokens):\n",
    "    log_prob0 = 0.0\n",
    "    log_prob1 = 0.0\n",
    "\n",
    "    for token in tokens:\n",
    "      if token in self.likelihoods:  # 학습 당시 추가했던 단어에 대해서만 고려.\n",
    "        log_prob0 += math.log(self.likelihoods[token][0])\n",
    "        log_prob1 += math.log(self.likelihoods[token][1])\n",
    "\n",
    "    # 마지막에 prior를 고려.\n",
    "    log_prob0 += math.log(self.priors[0])\n",
    "    log_prob1 += math.log(self.priors[1])\n",
    "\n",
    "    if log_prob0 >= log_prob1:\n",
    "      return 0\n",
    "    else:\n",
    "      return 1\n",
    "\n",
    "  # set_priors는 단순히 label의 비율을 계산 -> 해당 class의 개수가 많으면 비율도 높아짐\n",
    "  def set_priors(self, train_labels):\n",
    "    class_counts = Counter(train_labels)\n",
    "    \n",
    "    for label, count in class_counts.items():\n",
    "      self.priors[label] = class_counts[label] / len(train_labels)\n",
    "\n",
    "  def set_likelihoods(self, train_tokenized, train_labels):\n",
    "    token_dists = {}  # 각 단어의 특정 class 조건 하에서의 등장 횟수.\n",
    "    class_counts = defaultdict(int)  # 특정 class에서 등장한 모든 단어의 등장 횟수.\n",
    "\n",
    "    for tokens, label in zip(train_tokenized, tqdm(train_labels)):\n",
    "      count = 0\n",
    "      for token in tokens:\n",
    "        if token in self.w2i:  # 학습 데이터로 구축한 vocab에 있는 token만 고려.\n",
    "          if token not in token_dists:\n",
    "            token_dists[token] = {0:0, 1:0}\n",
    "          token_dists[token][label] += 1\n",
    "          count += 1\n",
    "      class_counts[label] += count\n",
    "\n",
    "    for token, dist in tqdm(token_dists.items()):\n",
    "      if token not in self.likelihoods:\n",
    "        self.likelihoods[token] = {\n",
    "            # Laplace smoothing으로 '특정 클래스에서 특정 단어가 아예 등장하지 않더라도' 확률을 0이 아니도록 변환해줌\n",
    "            0:(token_dists[token][0] + self.k) / (class_counts[0] + len(self.w2i)*self.k),\n",
    "            1:(token_dists[token][1] + self.k) / (class_counts[1] + len(self.w2i)*self.k),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzjVUyBOQEJk"
   },
   "source": [
    "### **모델 학습**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HuE3mFM46VBP"
   },
   "source": [
    "모델 객체를 만들고 학습 데이터로 학습시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Wt-iUEVRNsRj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████▎      | 9/10 [00:00<00:00, 66459.04it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████| 66/66 [00:00<00:00, 422632.16it/s]\n"
     ]
    }
   ],
   "source": [
    "classifier = NaiveBayesClassifier(w2i)\n",
    "classifier.train(train_tokenized, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h79XWrsnQJtN"
   },
   "source": [
    "### **테스트**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pjk05W136d5o"
   },
   "source": [
    "Test sample에 대한 결과는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Fe-fOScGNzH3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 40136.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['정말', '좋았습니다', '.', '또', '가고', '싶네요', '.']\n",
      "['별로', '였습니다', '.', '되도록', '가지', '마세요', '.']\n",
      "['다른', '분', '들께도', '추천', '드릴', '수', '있을', '만큼', '만족했습니다', '.']\n",
      "['서비스', '가', '좀', '더', '개선', '되었으면', '좋겠습니다', '.', '기분', '이', '좀', '나빴습니다', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "for test_tokens in tqdm(test_tokenized):\n",
    "    print(test_tokens)\n",
    "    pred = classifier.inference(test_tokens)\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "hrYMTKM10vYk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxQQ5Jp7yAJq"
   },
   "source": [
    "###**콘텐츠 라이선스**\n",
    "\n",
    "<font color='red'><b>**WARNING**</b></font> : **본 교육 콘텐츠의 지식재산권은 재단법인 네이버커넥트에 귀속됩니다. 본 콘텐츠를 어떠한 경로로든 외부로 유출 및 수정하는 행위를 엄격히 금합니다.** 다만, 비영리적 교육 및 연구활동에 한정되어 사용할 수 있으나 재단의 허락을 받아야 합니다. 이를 위반하는 경우, 관련 법률에 따라 책임을 질 수 있습니다.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "07544d16255252da9b8ecd1a17151ac17e18202afa68bff28e41c43d715b521f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
