{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0M47aJDTXtbL"
   },
   "source": [
    "##**4. LSTM, GRU**\n",
    "1. 기존 RNN과 다른 부분에 대해서 배웁니다.\n",
    "2. 이전 실습에 이어 다양한 적용법을 배웁니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBoAWPAJSI2D"
   },
   "source": [
    "### **필요 패키지 import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vEnlDHarWusL"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sze4MVwxSYPR"
   },
   "source": [
    "### **데이터 전처리**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugKWDpQrSY3o"
   },
   "source": [
    "아래의 sample data를 확인해봅시다.  \n",
    "이전 실습과 동일합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IWjwZOmGYMhw"
   },
   "outputs": [],
   "source": [
    "vocab_size = 100\n",
    "pad_id = 0\n",
    "\n",
    "data = [\n",
    "  [85,14,80,34,99,20,31,65,53,86,3,58,30,4,11,6,50,71,74,13],\n",
    "  [62,76,79,66,32],\n",
    "  [93,77,16,67,46,74,24,70],\n",
    "  [19,83,88,22,57,40,75,82,4,46],\n",
    "  [70,28,30,24,76,84,92,76,77,51,7,20,82,94,57],\n",
    "  [58,13,40,61,88,18,92,89,8,14,61,67,49,59,45,12,47,5],\n",
    "  [22,5,21,84,39,6,9,84,36,59,32,30,69,70,82,56,1],\n",
    "  [94,21,79,24,3,86],\n",
    "  [80,80,33,63,34,63],\n",
    "  [87,32,79,65,2,96,43,80,85,20,41,52,95,50,35,96,24,80]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FmqlfxW_Tsfm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 163840.00it/s]\n"
     ]
    }
   ],
   "source": [
    "max_len = len(max(data, key=len))\n",
    "print(f\"Maximum sequence length: {max_len}\")\n",
    "\n",
    "valid_lens = []\n",
    "for i, seq in enumerate(tqdm(data)):\n",
    "  valid_lens.append(len(seq))\n",
    "  if len(seq) < max_len:\n",
    "    data[i] = seq + [pad_id] * (max_len - len(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "znWCR7UbTvVE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[85, 14, 80, 34, 99, 20, 31, 65, 53, 86,  3, 58, 30,  4, 11,  6, 50, 71,\n",
      "         74, 13],\n",
      "        [58, 13, 40, 61, 88, 18, 92, 89,  8, 14, 61, 67, 49, 59, 45, 12, 47,  5,\n",
      "          0,  0],\n",
      "        [87, 32, 79, 65,  2, 96, 43, 80, 85, 20, 41, 52, 95, 50, 35, 96, 24, 80,\n",
      "          0,  0],\n",
      "        [22,  5, 21, 84, 39,  6,  9, 84, 36, 59, 32, 30, 69, 70, 82, 56,  1,  0,\n",
      "          0,  0],\n",
      "        [70, 28, 30, 24, 76, 84, 92, 76, 77, 51,  7, 20, 82, 94, 57,  0,  0,  0,\n",
      "          0,  0],\n",
      "        [19, 83, 88, 22, 57, 40, 75, 82,  4, 46,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0],\n",
      "        [93, 77, 16, 67, 46, 74, 24, 70,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0],\n",
      "        [94, 21, 79, 24,  3, 86,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0],\n",
      "        [80, 80, 33, 63, 34, 63,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0],\n",
      "        [62, 76, 79, 66, 32,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0]])\n",
      "tensor([20, 18, 18, 17, 15, 10,  8,  6,  6,  5])\n"
     ]
    }
   ],
   "source": [
    "# B: batch size, L: maximum sequence length\n",
    "batch = torch.LongTensor(data)  # (B, L)\n",
    "batch_lens = torch.LongTensor(valid_lens)  # (B)\n",
    "\n",
    "batch_lens, sorted_idx = batch_lens.sort(descending=True)\n",
    "batch = batch[sorted_idx]\n",
    "\n",
    "print(batch)\n",
    "print(batch_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPRtdhHoUKhH"
   },
   "source": [
    "### **LSTM 사용**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l1FvfENCUqYN"
   },
   "source": [
    "LSTM에선 cell state가 추가됩니다.  \n",
    "Cell state의 shape는 hidden state의 그것과 동일합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Q76VGoCCUrcQ"
   },
   "outputs": [],
   "source": [
    "embedding_size = 256\n",
    "hidden_size = 512\n",
    "num_layers = 1\n",
    "num_dirs = 1\n",
    "\n",
    "embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "lstm = nn.LSTM(\n",
    "    input_size=embedding_size,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "    bidirectional=True if num_dirs > 1 else False\n",
    ")\n",
    "\n",
    "h_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (num_layers * num_dirs, B, d_h)\n",
    "c_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (num_layers * num_dirs, B, d_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 512])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_0 == h_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "uhS7qvIKWYYb"
   },
   "outputs": [],
   "source": [
    "# d_w: word embedding size\n",
    "batch_emb = embedding(batch)  # (B, L, d_w)\n",
    "\n",
    "packed_batch = pack_padded_sequence(batch_emb.transpose(0, 1), batch_lens)\n",
    "\n",
    "packed_outputs, (h_n, c_n) = lstm(packed_batch, (h_0, c_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "uhS7qvIKWYYb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[ 0.1288,  0.0810,  0.0717,  ...,  0.0009,  0.0555, -0.1259],\n",
       "        [ 0.0678, -0.0109,  0.0860,  ..., -0.0908, -0.0636,  0.0780],\n",
       "        [-0.0351,  0.1051, -0.0605,  ...,  0.0954,  0.0735,  0.0010],\n",
       "        ...,\n",
       "        [ 0.1678, -0.0224,  0.1283,  ...,  0.1792,  0.1592,  0.1147],\n",
       "        [-0.1584,  0.1448,  0.1870,  ..., -0.1245,  0.0481,  0.1308],\n",
       "        [ 0.0462, -0.0336,  0.2350,  ..., -0.0415,  0.1065, -0.0899]],\n",
       "       grad_fn=<CatBackward0>), batch_sizes=tensor([10, 10, 10, 10, 10,  9,  7,  7,  6,  6,  5,  5,  5,  5,  5,  4,  4,  3,\n",
       "         1,  1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "uhS7qvIKWYYb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([123, 512])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_outputs[0].shape # (패딩 없는 실제 데이터 총 길이(총 단어수), h_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "uhS7qvIKWYYb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 512])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "uhS7qvIKWYYb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 512])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ArOrgjHjZqAa"
   },
   "outputs": [],
   "source": [
    "outputs, output_lens = pad_packed_sequence(packed_outputs)\n",
    "print(outputs.shape)\n",
    "print(output_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "meuNwIIn-H-g"
   },
   "source": [
    "### **GRU 사용**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMUysrtLihqt"
   },
   "source": [
    "GRU는 cell state가 없어 RNN과 동일하게 사용 가능합니다.   \n",
    "GRU를 이용하여 LM task를 수행해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ZHw8PSf--lVg"
   },
   "outputs": [],
   "source": [
    "gru = nn.GRU(\n",
    "    input_size=embedding_size,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "    bidirectional=True if num_dirs > 1 else False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "GbMy2CkWzobD"
   },
   "outputs": [],
   "source": [
    "output_layer = nn.Linear(hidden_size, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "YavlcFZywCBK"
   },
   "outputs": [],
   "source": [
    "input_id = batch.transpose(0, 1)[0, :]  # (B)\n",
    "hidden = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (1, B, d_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1tFGyvo-uHb"
   },
   "source": [
    "Teacher forcing 없이 이전에 얻은 결과를 다음 input으로 이용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "J6HRC3TAxtGa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Time step: 0\n",
      "torch.Size([1, 10, 100])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "**************************************************\n",
      "Time step: 1\n",
      "torch.Size([1, 10, 100])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "**************************************************\n",
      "Time step: 2\n",
      "torch.Size([1, 10, 100])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "**************************************************\n",
      "Time step: 3\n",
      "torch.Size([1, 10, 100])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "**************************************************\n",
      "Time step: 4\n",
      "torch.Size([1, 10, 100])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "**************************************************\n",
      "Time step: 5\n",
      "torch.Size([1, 10, 100])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "**************************************************\n",
      "Time step: 6\n",
      "torch.Size([1, 10, 100])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "**************************************************\n",
      "Time step: 7\n",
      "torch.Size([1, 10, 100])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "**************************************************\n",
      "Time step: 8\n",
      "torch.Size([1, 10, 100])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "**************************************************\n",
      "Time step: 9\n",
      "torch.Size([1, 10, 100])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "**************************************************\n",
      "Time step: 10\n",
      "torch.Size([1, 10, 100])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "**************************************************\n",
      "Time step: 11\n",
      "torch.Size([1, 10, 100])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "**************************************************\n",
      "Time step: 12\n",
      "torch.Size([1, 10, 100])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "**************************************************\n",
      "Time step: 13\n",
      "torch.Size([1, 10, 100])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "**************************************************\n",
      "Time step: 14\n",
      "torch.Size([1, 10, 100])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "**************************************************\n",
      "Time step: 15\n",
      "torch.Size([1, 10, 100])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "**************************************************\n",
      "Time step: 16\n",
      "torch.Size([1, 10, 100])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "**************************************************\n",
      "Time step: 17\n",
      "torch.Size([1, 10, 100])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "**************************************************\n",
      "Time step: 18\n",
      "torch.Size([1, 10, 100])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n",
      "**************************************************\n",
      "Time step: 19\n",
      "torch.Size([1, 10, 100])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "for t in range(max_len):\n",
    "  input_emb = embedding(input_id).unsqueeze(0)  # (1, B, d_w)\n",
    "  output, hidden = gru(input_emb, hidden)  # output: (1, B, d_h), hidden: (1, B, d_h)\n",
    "\n",
    "  # V: vocab size\n",
    "  output = output_layer(output)  # (1, B, V)\n",
    "  probs, top_id = torch.max(output, dim=-1)  # probs: (1, B), top_id: (1, B)\n",
    "\n",
    "  print(\"*\" * 50)\n",
    "  print(f\"Time step: {t}\")\n",
    "  print(output.shape)\n",
    "  print(probs.shape)\n",
    "  print(top_id.shape)\n",
    "\n",
    "  input_id = top_id.squeeze(0)  # (B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WY3vh9Cm4KaH"
   },
   "source": [
    "`max_len`만큼의 for 문을 돌면서 모든 결과물의 모양을 확인했지만 만약 종료 조건(예를 들어 문장의 끝을 나타내는 end token 등)이 되면 중간에 생성을 그만둘 수도 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l07L_QncemE7"
   },
   "source": [
    "### **양방향 및 여러 layer 사용**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lasjjz-teohw"
   },
   "source": [
    "이번엔 양방향 + 2개 이상의 layer를 쓸 때 얻을 수 있는 결과에 대해 알아봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "JEy00WX3ghsb"
   },
   "outputs": [],
   "source": [
    "num_layers = 2\n",
    "num_dirs = 2\n",
    "dropout=0.1\n",
    "\n",
    "gru = nn.GRU(\n",
    "    input_size=embedding_size,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout,\n",
    "    bidirectional=True if num_dirs > 1 else False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QX4LVL_Ag4kK"
   },
   "source": [
    "Bidirectional이 되었고 layer의 개수가 $2$로 늘었기 때문에 hidden state의 shape도 `(4, B, d_h)`가 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Q8aBk8yrfOHU"
   },
   "outputs": [],
   "source": [
    "# d_w: word embedding size, num_layers: layer의 개수, num_dirs: 방향의 개수\n",
    "batch_emb = embedding(batch)  # (B, L, d_w)\n",
    "h_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (num_layers * num_dirs, B, d_h) = (4, B, d_h)\n",
    "\n",
    "packed_batch = pack_padded_sequence(batch_emb.transpose(0, 1), batch_lens)\n",
    "\n",
    "packed_outputs, h_n = gru(packed_batch, h_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Q8aBk8yrfOHU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[ 0.0298,  0.0039, -0.0505,  ...,  0.0174, -0.0399,  0.1782],\n",
       "        [ 0.0672,  0.0723,  0.1700,  ...,  0.1121,  0.0232,  0.0243],\n",
       "        [-0.1066,  0.1780, -0.0096,  ...,  0.0701,  0.0344,  0.0226],\n",
       "        ...,\n",
       "        [ 0.1464, -0.0696,  0.0491,  ..., -0.1093,  0.0057, -0.0259],\n",
       "        [ 0.1276, -0.1609, -0.1486,  ...,  0.0088, -0.0297, -0.0266],\n",
       "        [ 0.1326, -0.2341, -0.1868,  ...,  0.0279, -0.0313, -0.1149]],\n",
       "       grad_fn=<CatBackward0>), batch_sizes=tensor([10, 10, 10, 10, 10,  9,  7,  7,  6,  6,  5,  5,  5,  5,  5,  4,  4,  3,\n",
       "         1,  1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Q8aBk8yrfOHU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([123, 1024])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Q8aBk8yrfOHU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 512])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "VQdVtMcehndm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 10, 1024])\n",
      "tensor([20, 18, 18, 17, 15, 10,  8,  6,  6,  5])\n"
     ]
    }
   ],
   "source": [
    "outputs, output_lens = pad_packed_sequence(packed_outputs)\n",
    "\n",
    "print(outputs.shape)  # (L, B, num_dirs*d_h)\n",
    "print(output_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "byuggMjekUxS"
   },
   "source": [
    "각각의 결과물의 shape는 다음과 같습니다.\n",
    "\n",
    "`outputs`: `(max_len, batch_size, num_dir * hidden_size)`  \n",
    "`h_n`: `(num_layers*num_dirs, batch_size, hidden_size)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "HaXhvyHjmFR3"
   },
   "outputs": [],
   "source": [
    "batch_size = h_n.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "HaXhvyHjmFR3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.4195,  0.1477,  0.0096,  ..., -0.1743,  0.1848, -0.0854],\n",
       "          [-0.1352, -0.2079, -0.0161,  ...,  0.1982,  0.1403,  0.2232],\n",
       "          [-0.2249,  0.2340,  0.5877,  ..., -0.0396, -0.1890, -0.4129],\n",
       "          ...,\n",
       "          [-0.1610,  0.2320,  0.3619,  ...,  0.1845, -0.0433,  0.1728],\n",
       "          [-0.3976,  0.2420, -0.2093,  ..., -0.3422, -0.0767,  0.0779],\n",
       "          [-0.4428, -0.0187,  0.0433,  ..., -0.3104, -0.0829, -0.0877]],\n",
       "\n",
       "         [[-0.0666,  0.0319, -0.0342,  ...,  0.0834,  0.1865,  0.1134],\n",
       "          [ 0.3491, -0.0077, -0.1411,  ..., -0.1849,  0.0924, -0.0364],\n",
       "          [ 0.1105, -0.0031,  0.0369,  ..., -0.5109,  0.0167, -0.1582],\n",
       "          ...,\n",
       "          [-0.0015, -0.3552, -0.0852,  ..., -0.0170,  0.1921, -0.1876],\n",
       "          [-0.1492, -0.2240, -0.6237,  ...,  0.1862, -0.1836, -0.1919],\n",
       "          [ 0.0779, -0.0264, -0.3977,  ...,  0.0978, -0.2226,  0.1559]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1326, -0.2341, -0.1868,  ..., -0.0324,  0.2228,  0.1212],\n",
       "          [ 0.1068,  0.0321, -0.0042,  ..., -0.0604,  0.0551,  0.1976],\n",
       "          [ 0.1464, -0.0696,  0.0491,  ..., -0.1380,  0.2743, -0.0901],\n",
       "          ...,\n",
       "          [ 0.1251, -0.0078, -0.0624,  ...,  0.1211,  0.1348,  0.0281],\n",
       "          [-0.2657,  0.0749,  0.0572,  ..., -0.3445, -0.0352, -0.2473],\n",
       "          [ 0.0050,  0.0555, -0.0755,  ..., -0.0301,  0.0850,  0.2938]],\n",
       "\n",
       "         [[-0.1093,  0.0046,  0.0189,  ...,  0.0174, -0.0399,  0.1782],\n",
       "          [-0.0198, -0.1413,  0.0302,  ...,  0.1121,  0.0232,  0.0243],\n",
       "          [ 0.1280, -0.0533,  0.0228,  ...,  0.0701,  0.0344,  0.0226],\n",
       "          ...,\n",
       "          [ 0.1166,  0.0724, -0.0232,  ...,  0.0129, -0.0523, -0.0237],\n",
       "          [-0.0572, -0.0926,  0.0384,  ..., -0.1343,  0.0228,  0.1640],\n",
       "          [ 0.1248, -0.1652,  0.0771,  ..., -0.0728,  0.0448,  0.0070]]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_n.view(num_layers, num_dirs, batch_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "HaXhvyHjmFR3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 10, 512])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_n.view(num_layers, num_dirs, batch_size, hidden_size).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0BpPGPvyG-E"
   },
   "source": [
    "###**콘텐츠 라이선스**\n",
    "\n",
    "<font color='red'><b>**WARNING**</b></font> : **본 교육 콘텐츠의 지식재산권은 재단법인 네이버커넥트에 귀속됩니다. 본 콘텐츠를 어떠한 경로로든 외부로 유출 및 수정하는 행위를 엄격히 금합니다.** 다만, 비영리적 교육 및 연구활동에 한정되어 사용할 수 있으나 재단의 허락을 받아야 합니다. 이를 위반하는 경우, 관련 법률에 따라 책임을 질 수 있습니다.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ml2",
   "language": "python",
   "name": "ml2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "aff83ea1928dcc0287770e0ea68916ae9727a33d95a26ca69018331bcc2781f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
