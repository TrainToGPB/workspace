{"cells":[{"cell_type":"markdown","metadata":{"id":"ClMpdyDd9kwD"},"source":["# Natural Language Processing\n","## 심화과제 2: Training NMT model with fairseq\n","\n","> 본 과제는 NLP 심화구현 해보고자 하는 사람들을 위한 과제입니다.\n",">\n","> 정답이나 Reference 코드가 존재하지 않으므로 가능한 곳까지 도전해보세요!"]},{"cell_type":"markdown","metadata":{"id":"EG739lm_VFfq"},"source":["### Introduction\n","\n","- 본 과제의 목적은 대표적인 pytorch library 중 하나인 fairseq을 이용해 번역 모델을 학습하는 방법을 배우는 것입니다.\n","- 일반적으로 우리는 해당 task와 관련되어 널리 알려진 라이브러리를 이용해 모델을 구현하고 tuning하게 됩니다. 자연어 처리 관련 여러 라이브러리가 있지만 번역 task에서 가장 자주 활용되고 있는 fairseq을 소개해드리고자 합니다.\n","- fairseq은 pytorch를 개발하고 있는 facebook에서 작업 중인 오픈소스 프로젝트 입니다. 라이브러리의 이름처럼 sequence를 다루는 데에 필요한 여러 모델과 전처리, 평가 관련 코드를 포함해 인기가 많은 library 중 하나입니다.\n","- 이번 시간에는 해당 라이브러리의 [docs](https://fairseq.readthedocs.io/en/latest/)를 직접 읽어보면서 목표 perplexity/BLEU를 달성하는 것이 목표입니다. 프로젝트에 대한 대략적인 설명과 관련 docs 링크를 함께 제공해드리겠습니다.\n","- 주어진 데이터에 대해 **BLEU score 25 이상**을 달성해보세요 !\n","- ***먼저 colab 상단 탭 runtime -> change runtime type에서 hardware accelerator를 GPU로 변경해주세요***"]},{"cell_type":"markdown","metadata":{"id":"wEzBG3v4VFfr"},"source":["### 0. 환경 셋팅 및 데이터 업로드"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hVhaiX9q06JN"},"outputs":[],"source":["# 필요 패키지 설치 (참고: 느낌표를 앞에 붙이면 해당 코드가 terminal에서 실행됩니다.)\n","!pip install fastBPE sacremoses subword_nmt hydra-core omegaconf fairseq"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"czKQJ-9A3bLB"},"outputs":[],"source":["# clone fairseq git\n","!git clone https://github.com/pytorch/fairseq.git\n","# iwslt14 데이터 준비 (https://github.com/pytorch/fairseq/blob/master/examples/translation/prepare-iwslt14.sh)\n","!bash fairseq/examples/translation/prepare-iwslt14.sh"]},{"cell_type":"markdown","metadata":{"id":"ROBHdpyLDHQT"},"source":["## 1. 라이브러리 참고 사항\n","1. [tasks](https://fairseq.readthedocs.io/en/latest/tasks.html): 번역 과제와 언어 모델링 과제가 있고 나머지 sequence를 다루는 과제는 register_task() function decorator를 이용해 등록할 수 있습니다.\n","2. [models](https://fairseq.readthedocs.io/en/latest/models.html): 모델은 CNN, LSTM, Transformer 기반 모델들이 분류가 되어 있습니다. transformer 모델쪽 코드가 꼼꼼히 잘되어 있습니다. 새로운 모델을 등록하기 위해서는 register_model() function decorator를 이용할 수 있습니다.\n","3. [criterions](https://fairseq.readthedocs.io/en/latest/criterions.html): 모델 학습을 위한 다양한 loss들이 구현되어 있습니다.\n","4. [optimizers](https://fairseq.readthedocs.io/en/latest/optim.html): 모델 학습을 위한 다양한 optimizer들이 구현되어 있습니다.\n","5. [learning rate schedulers](https://fairseq.readthedocs.io/en/latest/lr_scheduler.html): 모델의 더 나은 학습을 위한 다양한 learning rate scheduler들이 구현되어 있습니다.\n","6. [data loading and utilities](https://fairseq.readthedocs.io/en/latest/data.html): 전처리 및 데이터 관련 다양한 class들이 구현되어 있습니다.\n","7. [modules](https://fairseq.readthedocs.io/en/latest/modules.html): 앞의 6군데에 속하지 못한(?) 다양한 모듈들이 구현되어 있습니다."]},{"cell_type":"markdown","metadata":{"id":"161FFtZEFS47"},"source":["### 2. [명령줄 도구](https://fairseq.readthedocs.io/en/latest/command_line_tools.html)\n","fairseq은 학습과 평가를 쉽게할 수 있는 명령줄 도구(command-line tool)를 제공하고 있습니다\n","각각의 커맨드라인에 대한 설명은 위 링크에 자세히 나와있으니 참고해주시기 바랍니다.\n","1. fairseq-preprocess: 데이터 학습을 위한 vocab을 만들고 data를 구성합니다.\n","2. fairseq-train: 여러 gpu 또는 단일 gpu에서 모델을 학습시킵니다.\n","3. fairseq-generate: 학습된 모델을 이용해 전처리된 데이터를 번역합니다.\n","4. fairseq-interactive: 학습된 모델을 이용해 raw 데이터를 번역합니다.\n","5. fairseq-score: 학습된 모델이 생성한 문장과 정답 문장을 비교해 bleu score를 산출합니다.\n","6. fairseq-eval-lm: language model을 평가할 수 있는 command입니다.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5kyIs3dmBdVG"},"outputs":[],"source":["# 예시 코드를 이용해 직접 전처리부터 평가까지 진행해보겠습니다.\n","# source-lang: source language\n","# target-lang: target language\n","# trainpref: train file prefix\n","# validpref: valid file prefix\n","# testpref: test file prefix\n","# destdir: destination dir\n","!fairseq-preprocess --source-lang de --target-lang en --trainpref ./iwslt14.tokenized.de-en/train --validpref ./iwslt14.tokenized.de-en/valid --testpref ./iwslt14.tokenized.de-en/test --destdir ./iwslt14.tokenized.de-en/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iLJewb8r8btk"},"outputs":[],"source":["# 모델 학습\n","# (참고: 모델을 동시에 여러개 학습 시키고 싶으신 분들은 노트북 파일을 드라이브에 여러개 복사해서 각 파일마다 실행하면 여러 모델을 동시에 학습시킬 수 있습니다.)\n","# --arch: architecture\n","# --optimizer: optimizer {adadelta, adam, adafactor, adagrad, lamb, composite, nag, adamax, sgd}\n","# --clip-norm: clip threshold of gradients\n","# --lr: learning rate\n","# --lr-scheduler: learning rate scheduler {pass_through, cosine, reduce_lr_on_plateau, fixed, triangular, polynomial_decay, tri_stage, manual, inverse_sqrt}\n","# --criterion loss function {sentence_prediction, ctc, adaptive_loss, label_smoothed_cross_entropy, composite_loss, nat_loss, masked_lm, sentence_ranking, legacy_masked_lm_loss, cross_entropy, model, wav2vec, label_smoothed_cross_entropy_with_alignment, vocab_parallel_cross_entropy}\n","# --max-tokens: maximum number of tokens in a batch\n","# --max-epoch: maximum number of training epoch\n","\n","!fairseq-train ./iwslt14.tokenized.de-en/ --arch transformer_iwslt_de_en --optimizer adam --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --criterion label_smoothed_cross_entropy --max-tokens 4096 --max-epoch 3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QSCtWjJYFBEC"},"outputs":[],"source":[" # 예측 문장 생성 및 평가\n"," # checkpoints 폴더에 epoch마다 모델이 저장되고 best checkpoint는 checkpoint_best.pt라는 이름으로 저장됩니다\n","!fairseq-generate ./iwslt14.tokenized.de-en --path ./checkpoints/checkpoint_best.pt --beam 5 --remove-bpe"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kLJrMdptUdTT"},"outputs":[],"source":["# 여러분만의 모델을 학습해 목표 BLEU score를 달성해주세요 ! \n","# command line tools: https://fairseq.readthedocs.io/en/latest/command_line_tools.html\n","# github: https://github.com/pytorch/fairseq"]},{"cell_type":"markdown","metadata":{"id":"aGA28R2NbbmH"},"source":["###**콘텐츠 라이선스**\n","\n","<font color='red'><b>**WARNING**</b></font> : **본 교육 콘텐츠의 지식재산권은 재단법인 네이버커넥트에 귀속됩니다. 본 콘텐츠를 어떠한 경로로든 외부로 유출 및 수정하는 행위를 엄격히 금합니다.** 다만, 비영리적 교육 및 연구활동에 한정되어 사용할 수 있으나 재단의 허락을 받아야 합니다. 이를 위반하는 경우, 관련 법률에 따라 책임을 질 수 있습니다.\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.9.12 ('base')","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.9.12"},"vscode":{"interpreter":{"hash":"aff83ea1928dcc0287770e0ea68916ae9727a33d95a26ca69018331bcc2781f6"}}},"nbformat":4,"nbformat_minor":0}